@article{Stacking,
author = {öz, Ersoy and Bulut, Okan and Cellat, Zuhal Fatma and Yürekli, Hülya},
year = {2024},
month = {10},
pages = {1-27},
title = {Stacking: An ensemble learning approach to predict student performance in PISA 2022},
journal = {Education and Information Technologies},
doi = {10.1007/s10639-024-13110-2}
}

@article{WOLPERT1992241,
title = {Stacked generalization},
journal = {Neural Networks},
volume = {5},
number = {2},
pages = {241-259},
year = {1992},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(05)80023-1},
url = {https://www.sciencedirect.com/science/article/pii/S0893608005800231},
author = {David H. Wolpert},
keywords = {Generalization and induction, Combining generalizers, Learning set preprocessing, cross-validation, Error estimation and correction},
abstract = {This paper introduces stacked generalization, a scheme for minimizing the generalization error rate of one or more generalizers. Stacked generalization works by deducing the biases of the generalizer(s) with respect to a provided learning set. This deduction proceeds by generalizing in a second space whose inputs are (for example) the guesses of the original generalizers when taught with part of the learning set and trying to guess the rest of it, and whose output is (for example) the correct guess. When used with multiple generalizers, stacked generalization can be seen as a more sophisticated version of cross-validation, exploiting a strategy more sophisticated than cross-validation's crude winner-takes-all for combining the individual generalizers. When used with a single generalizer, stacked generalization is a scheme for estimating (and then correcting for) the error of a generalizer which has been trained on a particular learning set and then asked a particular question. After introducing stacked generalization and justifying its use, this paper presents two numerical experiments. The first demonstrates how stacked generalization improves upon a set of separate generalizers for the NETtalk task of translating text to phonemes. The second demonstrates how stacked generalization improves the performance of a single surface-fitter. With the other experimental evidence in the literature, the usual arguments supporting cross-validation, and the abstract justifications presented in this paper, the conclusion is that for almost any real-world generalization problem one should use some version of stacked generalization to minimize the generalization error rate. This paper ends by discussing some of the variations of stacked generalization, and how it touches on other fields like chaos theory.}
}

@article{CUI2021107038,
title = {A stacking-based ensemble learning method for earthquake casualty prediction},
journal = {Applied Soft Computing},
volume = {101},
pages = {107038},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.107038},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620309765},
author = {Shaoze Cui and Yunqiang Yin and Dujuan Wang and Zhiwu Li and Yanzhang Wang},
keywords = {Earthquake, Casualty prediction, Ensemble learning, Stacking, Intelligent optimization algorithm},
abstract = {The estimation of the loss and prediction of the casualties in earthquake-stricken areas are vital for making rapid and accurate decisions during rescue efforts. The number of casualties is determined by various factors, necessitating a comprehensive system for earthquake-casualty prediction. To obtain accurate prediction results, an effective prediction method based on stacking ensemble learning and improved swarm intelligence algorithm is proposed in this study, which comprises three parts: (1) applying multiple base learners for training, (2) using a stacking strategy to integrate the results generated by multiple base learners to obtain the final prediction results, and (3) developing an improved swarm intelligence algorithm to optimize the key parameters in the prediction model. To verify the effectiveness of the model, we collected data pertaining to earthquake destruction from 1966 to 2017 in China. Experiments were conducted to compare the proposed method with popular machine learning methods. It was found that the stacking ensemble learning method can effectively integrate the prediction results of the base learner to improve the performance of the model, and the improved swarm intelligence algorithm can further improve the prediction accuracy. Moreover, the importance of each feature was evaluated, which has important implications for future work such as casualty prevention and rescue during earthquakes.}
}