{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercícios: Aprendizagem não supervisionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estes exercícios, será usado o conjunto de dados [Mall Customer Segmentation Data](https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/' if os.path.exists('../data/') else 'https://raw.githubusercontent.com/TheAwesomeGe/DECD/main/data/'\n",
    "csv_file_path = data_path + 'Mall_Customers.csv'\n",
    "df = pd.read_csv(csv_file_path, index_col='CustomerID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Comece por analisar os dados e compreender os vários atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Prepare os dados de forma a obter um conjunto que tenha apenas atributos numéricos. (**Nota**: Pode optar por descartar ou transformar os atributos que não sejam numéricos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df = df.drop(columns=['Gender'])\n",
    "prepared_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Analise a distribuição de cada um dos atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(prepared_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Aplique a abordagem PCA e visualize a projeção dos dados nos dois componentes principais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_df = pd.DataFrame(pca.fit_transform(prepared_df), index=prepared_df.index, columns=['PC1', 'PC2'])\n",
    "sns.scatterplot(pca_df, x='PC1', y='PC2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Verifique qual a percentagem da variância do conjunto de dados explicada pelos dois componentes principais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_.sum()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Utilize o algoritmo *k-Means* para agrupar os dados. Escolha um valor de *k* adequado e visualize o agrupamento obtido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_wss = pd.DataFrame([(k, KMeans(n_clusters=k, n_init='auto').fit(prepared_df).inertia_) for k in range(1, 11)], columns=['k', 'wss'])\n",
    "sns.lineplot(k_wss, x='k', y='wss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, n_init='auto').fit(prepared_df)\n",
    "sns.scatterplot(pca_df, x='PC1', y='PC2', hue=kmeans.labels_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Agrupe os dados usando *clustering* hierárquico aglomerativo e visualize o dendrograma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_full = AgglomerativeClustering(n_clusters=None, distance_threshold=0).fit(prepared_df)\n",
    "plot_dendrogram(hierarchical_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Selecione o mesmo número de clusters usado para o algoritmo *k-means* e compare os dois agrupamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_k = AgglomerativeClustering(n_clusters=5).fit(prepared_df)\n",
    "sns.scatterplot(pca_df, x='PC1', y='PC2', hue=kmeans.labels_).set(title='k-Means')\n",
    "plt.show()\n",
    "sns.scatterplot(pca_df, x='PC1', y='PC2', hue=hierarchical_k.labels_).set(title='Hierarchical Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Agrupe os dados usando o algoritmo *DBSCAN*. Explore e visualize os agrupamentos obtidos usando múltiplas parametrizações. Como varia o número de clusters e a percentagem de *outliers*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=15, min_samples=11).fit(prepared_df)\n",
    "print(f'Number of clusters: {len(set(dbscan.labels_) - {-1})}')\n",
    "print(f'Outliers: {sum(dbscan.labels_ == -1)*100 / len(dbscan.labels_)}%')\n",
    "sns.scatterplot(pca_df, x='PC1', y='PC2', hue=dbscan.labels_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Qual das três abordagens lhe parece produzir um agrupamento de melhor qualidade?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(index=['k-Means', 'Hierarchical Clustering', 'DBSCAN'])\n",
    "\n",
    "eval_df['Silhouette Coefficient'] = [sklearn.metrics.silhouette_score(prepared_df, c.labels_) for c in (kmeans, hierarchical_k, dbscan)]\n",
    "eval_df['Calinski-Harabasz Index'] = [sklearn.metrics.calinski_harabasz_score(prepared_df, c.labels_) for c in (kmeans, hierarchical_k, dbscan)]\n",
    "eval_df['Davies-Bouldin Index'] = [sklearn.metrics.davies_bouldin_score(prepared_df, c.labels_) for c in (kmeans, hierarchical_k, dbscan)]\n",
    "\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Verifique se normalizar os dados tem impacto no resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df = pd.DataFrame(StandardScaler().fit_transform(prepared_df), index=prepared_df.index, columns=prepared_df.columns)\n",
    "\n",
    "kmeans_norm = KMeans(n_clusters=5, n_init='auto').fit(normalized_df)\n",
    "\n",
    "print(f'Silhouette Coefficient: {sklearn.metrics.silhouette_score(normalized_df, kmeans_norm.labels_)}')\n",
    "print(f'Calinski-Harabasz Index: {sklearn.metrics.calinski_harabasz_score(normalized_df, kmeans_norm.labels_)}')\n",
    "print(f'Davies-Bouldin Index: {sklearn.metrics.davies_bouldin_score(normalized_df, kmeans_norm.labels_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Discretize os atributos originais e repita as experiências. (**Sugestão**: Use as funções [`cut`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html) e [`qcut`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html) da biblioteca *pandas*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_df = pd.DataFrame(index=prepared_df.index)\n",
    "\n",
    "discrete_df['Age'] = pd.cut(prepared_df['Age'], bins=[0, 18, 25, 45, 60, 70], labels=['minor', 'young', 'adult', 'experienced', 'elder'])\n",
    "discrete_df['Income'] = pd.qcut(prepared_df['Annual Income (k$)'], q=3, labels=['low', 'medium', 'high'])\n",
    "discrete_df['Spending Score'] = pd.cut(prepared_df['Spending Score (1-100)'], bins = 5, labels=['e', 'd', 'c', 'b', 'a'])\n",
    "\n",
    "discrete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_num = {f: {c: i for i, c in enumerate(discrete_df[f].cat.categories)} for f in discrete_df.columns}\n",
    "\n",
    "for f in discrete_df.columns:\n",
    "    discrete_df[f] = discrete_df[f].replace(cat_num[f]).astype('int')\n",
    "    \n",
    "discrete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_k_wss = pd.DataFrame([(k, KMeans(n_clusters=k, n_init='auto').fit(discrete_df).inertia_) for k in range(1, 11)], columns=['k', 'wss'])\n",
    "sns.lineplot(discrete_k_wss, x='k', y='wss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_kmeans = KMeans(n_clusters=4, n_init='auto').fit(discrete_df)\n",
    "kmeans_df = discrete_df.copy()\n",
    "kmeans_df['clusters'] = pd.Categorical(discrete_kmeans.labels_)\n",
    "sns.pairplot(kmeans_df, hue='clusters');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_hierarchical = AgglomerativeClustering(n_clusters=4).fit(discrete_df)\n",
    "hierarchical_df = discrete_df.copy()\n",
    "hierarchical_df['clusters'] = pd.Categorical(discrete_hierarchical.labels_)\n",
    "sns.pairplot(hierarchical_df, hue='clusters');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_dbscan = DBSCAN(eps=0.5, min_samples=11, metric='manhattan').fit(discrete_df)\n",
    "dbscan_df = discrete_df.copy()\n",
    "dbscan_df['clusters'] = pd.Categorical(discrete_dbscan.labels_)\n",
    "sns.pairplot(dbscan_df, hue='clusters');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_eval_df = pd.DataFrame(index=['k-Means', 'Hierarchical Clustering', 'DBSCAN'])\n",
    "\n",
    "discrete_eval_df['Silhouette Coefficient'] = [sklearn.metrics.silhouette_score(discrete_df, c) for c in (kmeans_df['clusters'], hierarchical_df['clusters'], dbscan_df['clusters'])]\n",
    "discrete_eval_df['Calinski-Harabasz Index'] = [sklearn.metrics.calinski_harabasz_score(discrete_df, c) for c in (kmeans_df['clusters'], hierarchical_df['clusters'], dbscan_df['clusters'])]\n",
    "discrete_eval_df['Davies-Bouldin Index'] = [sklearn.metrics.davies_bouldin_score(discrete_df, c) for c in (kmeans_df['clusters'], hierarchical_df['clusters'], dbscan_df['clusters'])]\n",
    "\n",
    "discrete_eval_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
