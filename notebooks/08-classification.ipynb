{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149092e9-7aed-4e97-9cc6-c370d6ff7ede",
   "metadata": {},
   "source": [
    "# Aprendizagem supervisionada: Classificação\n",
    "\n",
    "A aprendizagem supervisionada é um ramo da aprendizagem automática que se foca na construção de modelos capazes de prever ou classificar dados com base em exemplos etiquetados. A aprendizagem supervisionada abrange duas abordagens principais: classificação, usada para prever classes ou categorias discretas, e regressão, usada para prever valores contínuos. Tal como no caso da aprendizagem não supervisionada, em Python, a biblioteca [scikit-learn](https://scikit-learn.org/) é amplamente utilizada para implementar algoritmos de aprendizagem supervisionada e explorar técnicas de classificação, regressão e outras tarefas relacionadas. Este tutorial foca-se na aplicação e avaliação de diferentes algoritmos de classificação disponibilizados pela biblioteca *scikit-learn*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f86e187-ef0d-4932-8261-40b55dd631fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cec085-0899-4946-bdb7-bb89b4a2e8a8",
   "metadata": {},
   "source": [
    "Tal como para a aprendizagem não supervisionada, vamos usar o conjunto de dados [Iris](https://archive.ics.uci.edu/dataset/53/iris) como exemplo para a aplicação de abordagens de classificação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e364e-55e3-4e1a-87dd-a592db344dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "iris.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a8475d-ccb8-4e37-884f-e41793d529cd",
   "metadata": {},
   "source": [
    "## Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1fad8-77e0-4105-b03b-afcbca867e20",
   "metadata": {},
   "source": [
    "A classificação tem como objetivo prever o valor de um determinado atributo discreto (*target*). Como tal, temos de definir qual é o atributo que queremos prever. No caso do conjunto de dados *Iris*, o objetivo é identificar a espécie de planta, tendo como base as características das suas flores. Por isso, vamos separar o atributo `species` dos restantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e63b90-1e85-4e0e-aa30-05a1cd6cee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['species'].astype('category')\n",
    "X = iris.drop(columns=['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77067cff-bf08-4aa8-b625-59de80200e61",
   "metadata": {},
   "source": [
    "Para estimar o desempenho de modelos de classificação e avaliar a sua capacidade de generalização para dados que não foram vistos durante o treino, é necessário um conjunto de dados de teste que é colocado de parte durante a construção dos modelos.\n",
    "\n",
    "O conjunto de dados *Iris* não tem uma partição predefinida. Como tal, vamos usar a função `train_test_split` da biblioteca *scikit-learn* para particionar o conjunto. Neste caso, vamos usar 80% para treino e 20% para teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83ca45a-c447-4230-8f7b-c423b8364e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffde8e86-4c16-4981-bf91-b002763fa362",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e84b0b-0b4e-4b6c-8542-6bb24eff69f8",
   "metadata": {},
   "source": [
    "**Nota**: O argumento `random_state` é usado para que o resultado seja reprodutível."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9474c6-01da-4cfd-8545-8688eaa68fc3",
   "metadata": {},
   "source": [
    "Para visualizar os dois conjuntos, vamos usar PCA para obter os dois componentes principais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af8668-ebdd-4009-bbdf-2b1ee91dc3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "\n",
    "pca_train = pd.DataFrame(pca.transform(X_train), index=X_train.index, columns=['PC1', 'PC2'])\n",
    "sns.scatterplot(pca_train, x='PC1', y='PC2', hue=y_train)\n",
    "plt.title('Training Set')\n",
    "plt.show()\n",
    "\n",
    "pca_test = pd.DataFrame(pca.transform(X_test), index=X_test.index, columns=['PC1', 'PC2'])\n",
    "sns.scatterplot(pca_test, x='PC1', y='PC2', hue=y_test)\n",
    "plt.title('Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559b0892-1878-4973-83c9-6ac2bf82e966",
   "metadata": {},
   "source": [
    "**Nota**: Apesar de a decomposição estar a ser feita apenas para visualização, é boa prática que esta seja baseada apenas no conjunto de treino. Ambos os conjuntos podem depois ser transformados de acordo com essa decomposição."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54de308-5ac2-417d-bcca-1a95063cbf56",
   "metadata": {},
   "source": [
    "## Método de avaliação\n",
    "\n",
    "Para avaliar o desempenho de um modelo de classificação é necessário definir um conjunto de métricas relevantes para o problema que se está a abordar. A função `classification_report` da biblioteca *scikit-learn* recebe as classificações de um determinado conjunto de dados e as previsões de um classificador para o mesmo conjunto e produz um resumo com as métricas de avaliação mais comuns para tarefas de classificação: taxa de acerto, precisão, cobertura e F1-Score. Para além disso, dados os mesmos argumentos, a função `confusion_matrix` constrói a matriz de confusão entre as classificações reais e as previstas. Para simplificar, vamos definir uma função que combina estas duas e apresenta os resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22556394-bd3c-4b3e-9f75-7fc78b58e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "def display_evaluation(labels, predictions, class_names):\n",
    "    print(classification_report(labels, predictions, target_names=class_names))\n",
    "    cm = confusion_matrix(labels, predictions, labels=class_names)\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names).plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915013e-cdd2-4d61-89c3-01ba94dfa941",
   "metadata": {},
   "source": [
    "**Nota**: O argumento `output_dict=True` pode ser usado para que a função `classification_report` retorne os resultados na forma de um dicionário. Isto é útil para agregar os resultados de vários modelos e compará-los mais tarde."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13dce06-74e8-4b4b-94c4-ea09d80e7ad2",
   "metadata": {},
   "source": [
    "## Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de83ea-64c5-460f-b163-aacd5e26da32",
   "metadata": {},
   "source": [
    "Agora que temos o conjunto de dados particionado e definimos uma forma de avaliar o desempenho dos modelos, podemos começar a explorar algumas das abordagens de classificação disponibilizadas pela biblioteca *scikit-learn* de forma a treinar um conjunto de modelos que nos pareça adequado para o problema. No entanto, se olharmos para o desempenho de um modelo no mesmo conjunto de dados em que este foi treinado, os resultados vão estar inflacionados e não refletem a sua capacidade de generalização. Isto pode levar à seleção de modelos que acabam por ter um desempenho muito pior no conjunto de teste. Como tal, é costume fazer uma outra partição do conjunto de treino de forma a usar parte deste para validação. Desta forma, enquanto as diversas abordagens de classificação estão a ser exploradas, os modelos são treinados num subconjunto dos dados treino e avaliados nesse subconjunto de validação. As abordagens (e parametrizações) com melhor desempenho no conjunto de validação são então selecionadas, sendo o conjunto de treino completo usado para treinar novos modelos de acordo com essas configurações. Desta forma, é maximizada a quantidade de dados de treino usada para gerar os modelos que serão depois avaliados no conjunto de teste.\n",
    "\n",
    "Quando existem recursos (temporais/computacionais) suficientes, é possível fazer uma exploração mais completa, repetindo as experiências variando o conjunto de validação. A validação cruzada é uma técnica usada para fazer este tipo de exploração. Neste caso, o conjunto de treino é particionado em *k* subconjuntos e cada um deles é usado, à vez, como conjunto de validação enquanto os restantes são usados para treinar o modelo. A função `cross_val_score` da biblioteca *scikit-learn* aplica esta técnica automaticamente e devolve o valor da taxa de acerto para cada um dos *k* subconjuntos. Para calcular os valores de outras métricas, podemos usar a função `cross_val_predict` para obter as previsões para cada exemplo do conjunto de treino quando este faz parte do conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a90f5-db21-425a-a6e0-c683b3c25751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348d6e2-f211-41d7-80f7-cdaf75880900",
   "metadata": {},
   "source": [
    "Como vamos explorar diferentes tipos de algoritmos de classificação, vamos criar um dicionário para guardar o melhor classificador de cada tipo para mais tarde avaliar o seu desempenho no conjunto de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca54373-b86d-4804-845d-09e63ee7c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433342c3-53f8-45cf-af61-2f40d251a2a9",
   "metadata": {},
   "source": [
    "Dada a quantidade de algoritmos de classificação disponibilizada pela biblioteca *scikit-learn*, não vamos explorar a fundo todas as variações possíveis. No entanto, serão indicados alguns argumentos que podem ser usados para parametrizar as abordagens. O código disponível neste notebook pode ser alterado para explorar diferentes valores para esses argumentos, de forma a obter os modelos com melhor desempenho. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42290f4-7c38-4624-941a-722800bda02e",
   "metadata": {},
   "source": [
    "**Nota**: Como o processo de validação cruzada e muitos dos algoritmos de classificação incluem fatores não determinísticos, recomenda-se que sejam feitas múltiplas execuções para tomar decisões mais informadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e29559-de18-4bb3-a824-2105e7ba7985",
   "metadata": {},
   "source": [
    "### k-NN\n",
    "\n",
    "O algoritmo k-NN (k-Nearest Neighbors) é uma técnica simples de aprendizagem supervisionada. Tal como o nome indica, usando este algoritmo, a classificação de uma nova observação é determinada pelas classificações dos seus *k* vizinhos mais próximos. Na biblioteca *scikit-learn*, este algoritmo é implementado pela classe `KNeighborsClassifier`, sendo o número de vizinhos a considerar definido pelo argumento `n_neighbors`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff36a7-a778-4ff6-a973-9fb21b901ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419125b2-2ccb-4c8e-ae5d-7782cde9c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cls = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe33e638-794a-4956-9faa-dd7134c92a20",
   "metadata": {},
   "source": [
    "**Nota**: Por predefinição, a classificação é dada pela maioria das classificações dos vizinhos. O argumento `weights='distance'` pode ser usado para fazer uma ponderação com base na distância."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab72cd42-d083-418c-8c8d-e8437a67a5be",
   "metadata": {},
   "source": [
    "Vamos então usar a função `cross_val_predict` para aplicar uma técnica de validação cruzada e obter as previsões para todos os exemplos do conjunto de treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6fc917-eafc-4360-ad92-f1b5136bfe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cv_pred = cross_val_predict(knn_cls, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f180fb-7449-4762-b19a-7bb61731de71",
   "metadata": {},
   "source": [
    "Podemos usar a projeção nos dois componentes principais para visualizar as previsões corretas e incorretas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e6e343-e131-4170-909c-448fd3853b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(pca_train, x='PC1', y='PC2', \n",
    "                hue=knn_cv_pred==y_train, palette={True: 'green', False: 'red'}, \n",
    "                style=knn_cv_pred==y_train, markers={True: 'P', False: 'X'},\n",
    "                legend=False\n",
    "               );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7514143a-be62-4626-a7e8-2dc68cfadf11",
   "metadata": {},
   "source": [
    "E a função que definimos anteriormente para obter os resultados em termos das várias métricas e a matriz de confusão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb5a96-b4e3-486f-8d9d-63a121b9f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_evaluation(y_train, knn_cv_pred, y.cat.categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ccf10-c6c5-43d5-a206-d0f663b5a47a",
   "metadata": {},
   "source": [
    "Após encontrarmos a melhor configuração para o algoritmo, podemos treinar o modelo no conjunto de treino completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1447c-9b48-42c6-967c-3fe9e822f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['kNN'] = knn_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e71b71-6554-49dc-9d6c-508658ec40cc",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "O algoritmo Naive Bayes baseia-se no teorema de Bayes e assume independência condicional entre os vários atributos. Na biblioteca *scikit-learn* é implementado pela classe `GaussianNB`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ae6bc-b9ab-4ae3-bf94-390920e0fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0982ac8-4aee-42c7-bae6-f2f20a29b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cls = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d1969-96cc-48af-b42c-1d438d8d19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_cv_pred = cross_val_predict(nb_cls, X_train, y_train, cv=5)\n",
    "sns.scatterplot(pca_train, x='PC1', y='PC2', \n",
    "                hue=nb_cv_pred==y_train, palette={True: 'green', False: 'red'}, \n",
    "                style=nb_cv_pred==y_train, markers={True: 'P', False: 'X'},\n",
    "                legend=False\n",
    "               )\n",
    "plt.show()\n",
    "display_evaluation(y_train, nb_cv_pred, y.cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270d508-d8ad-4a03-94b1-34c9d5139657",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['Naive Bayes'] = nb_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb238a-44fe-44c9-8d00-aa1a7922d593",
   "metadata": {},
   "source": [
    "### Árvores de Decisão\n",
    "\n",
    "As árvores de decisão são uma técnica de aprendizagem supervisionada que se baseia na construção de uma estrutura em forma de árvore para representar decisões de acordo com os valores dos atributos e os seus resultados. A biblioteca *scikit-learn* implementa esta técnica na classe `DecisionTreeClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c710494b-6ccc-4508-8f42-4f7c36e753d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48783f58-30be-4d30-b785-0047737f51aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cls = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db63b8-eee7-413b-bcc5-6a4568b4e6e7",
   "metadata": {},
   "source": [
    "**Nota**: Por predefinição, é usada a [impureza de Gini](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity) como critério de seleção do atributo a testar em cada nó da árvore. Este critério pode ser substituído pela entropia usando o argumento `criterion='entropy'`. \n",
    "\n",
    "Para além disso, existem vários argumentos que podem ser usados para limitar a construção da árvore para evitar um sobreajustamento aos dados de treino. Por exemplo:\n",
    "\n",
    "- `max_depth`: Profundidade máxima da árvore\n",
    "- `min_samples_split`: Mínimo de exemplos necessários para continuar a tomar decisões\n",
    "- `max_features`: Máximo de atributos a testar\n",
    "\n",
    "Recomenda-se a consulta da [documentação da classe](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) para obter mais informação sobre as possibilidades de configuração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6b368-7bb8-475f-a7ca-7b0d8bb34ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cv_pred = cross_val_predict(dt_cls, X_train, y_train, cv=5)\n",
    "sns.scatterplot(pca_train, x='PC1', y='PC2', \n",
    "                hue=dt_cv_pred==y_train, palette={True: 'green', False: 'red'}, \n",
    "                style=dt_cv_pred==y_train, markers={True: 'P', False: 'X'},\n",
    "                legend=False\n",
    "               )\n",
    "plt.show()\n",
    "display_evaluation(y_train, dt_cv_pred, y.cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4edce-bdd6-4290-b05a-517e27e44799",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['Decision Tree'] = dt_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21c3eb-8959-4e32-99a0-103f01d17609",
   "metadata": {},
   "source": [
    "Após treinar um classificador baseado em árvores de decisão, a árvore pode ser visualizada usando a função `plot_tree`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72228447-d325-421f-9675-11bb795e383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733548d5-d9d4-439a-9b27-6998a6e6942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(dt_cls, feature_names=X_train.columns, class_names=dt_cls.classes_, impurity=False, rounded=True, filled=True, max_depth=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece9890c-2636-43a9-8bfc-16667dbc87b3",
   "metadata": {},
   "source": [
    "Este tipo de visualização é útil para identificar quais os atributos mais relevantes para a classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b06ec-9240-486a-b421-f43d8bbcd2da",
   "metadata": {},
   "source": [
    "#### Floresta Aleatória (Random Forest)\n",
    "\n",
    "O algoritmo Random Forest combina as previsões de múltiplas árvores de decisão treinadas usando subconjuntos aleatórios do conjunto de treino e dos atributos. Na biblioteca *scikit-learn*, o algoritmo é implementado pela classe `RandomForestClassifier`, sendo o número de árvores de decisão definido pelo atributo `n_estimators`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b7175-ada7-47ff-9796-bd741456ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b36ed-9670-46d4-bad2-68ee2d2ca2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cls = RandomForestClassifier(n_estimators=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec6db59-574a-495a-8463-8a8e7022dc97",
   "metadata": {},
   "source": [
    "**Nota**: As árvores de decisão podem ser parametrizadas usando os argumentos descritos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484b97a-f005-473e-a6d5-79d23121e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv_pred = cross_val_predict(rf_cls, X_train, y_train, cv=5)\n",
    "sns.scatterplot(pca_train, x='PC1', y='PC2', \n",
    "                hue=rf_cv_pred==y_train, palette={True: 'green', False: 'red'}, \n",
    "                style=rf_cv_pred==y_train, markers={True: 'P', False: 'X'},\n",
    "                legend=False\n",
    "               )\n",
    "plt.show()\n",
    "display_evaluation(y_train, rf_cv_pred, y.cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb9f15-bae9-4d44-a77d-89f7f56bfdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['Random Forest'] = rf_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2b31a6-ccd9-47e6-97b7-497c52d9a65c",
   "metadata": {},
   "source": [
    "### Regressão Logística\n",
    "\n",
    "Apesar do nome, a regressão logística é maioritariamente usada para classificação. Este algoritmo usa uma função logística para modelar a probabilidade de uma classe em relação aos atributos. Na biblioteca *scikit-learn* é implementado pela classe `LogisticRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aa7af6-b39f-49e9-a35e-018407825b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983400fb-c4b5-4ad5-a7e2-00ebacb4641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cls = LogisticRegression(max_iter=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c840d63-00b1-45f5-aee6-86d2045d7d04",
   "metadata": {},
   "source": [
    "**Nota**: Como os parâmetros do modelo são calculados usando abordagens de otimização incremental, é possível que não seja alcançada a convergência. O argumento `max_iter` é usado para definir o número máximo de iterações. Para além disso, os argumentos `penalty` e `C` podem ser usados para parametrizar a abordagem de regularização de pesos usada pelo algoritmo e evitar o sobreajustamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d57a228-aa45-4aef-80e6-ddefa6255337",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cv_pred = cross_val_predict(lr_cls, X_train, y_train, cv=5)\n",
    "sns.scatterplot(pca_train, x='PC1', y='PC2', \n",
    "                hue=lr_cv_pred==y_train, palette={True: 'green', False: 'red'}, \n",
    "                style=lr_cv_pred==y_train, markers={True: 'P', False: 'X'},\n",
    "                legend=False\n",
    "               )\n",
    "plt.show()\n",
    "display_evaluation(y_train, lr_cv_pred, y.cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ff64b-20a2-48a7-b07e-d70c04655598",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['Logistic Regression'] = lr_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e95d7d-53ad-4e36-839e-5317929c2e86",
   "metadata": {},
   "source": [
    "### Máquinas de Vetores de Suporte\n",
    "\n",
    "As máquinas de vetores de suporte (SVMs) são uma técnica de aprendizagem supervisionada que se foca em encontrar um hiperplano de separação que maximiza a margem entre classes. Na biblioteca *scikit-learn*, esta técnica é implementada pela classe `SVC`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221d095-59b4-40d8-a2ad-2f3cf866af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b124059-1a54-4350-bfa0-4116fd7855c8",
   "metadata": {},
   "source": [
    "#### Linear\n",
    "\n",
    "Na sua versão original e mais simples, uma máquina de vetor de suporte é um classificador linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473944e-0cd6-4578-b31a-3f77fd6cb152",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm_cls = SVC(kernel='linear', C=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a862c86-b555-4345-88c9-b347a59a4b35",
   "metadata": {},
   "source": [
    "**Nota**: O argumento `C` é usado para controlar a suavidade da margem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a58cc-d38f-4978-8a38-46b59b653bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm_cv_pred = cross_val_predict(linear_svm_cls, X_train, y_train, cv=5)\n",
    "sns.scatterplot(pca_train, x='PC1', y='PC2', \n",
    "                hue=linear_svm_cv_pred==y_train, palette={True: 'green', False: 'red'}, \n",
    "                style=linear_svm_cv_pred==y_train, markers={True: 'P', False: 'X'},\n",
    "                legend=False\n",
    "               )\n",
    "plt.show()\n",
    "display_evaluation(y_train, linear_svm_cv_pred, y.cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3464645-c716-4f9e-a97b-9f2872c90465",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['Linear SVM'] = linear_svm_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcd5af3-5840-43dc-b637-bd4b0706c283",
   "metadata": {},
   "source": [
    "#### Kernels\n",
    "\n",
    "O truque do kernel é uma técnica usada no contexto das máquinas de vetores de suporte para que estas sejam capazes de lidar com conjuntos de dados não linearmente separáveis. A ideia por trás do truque do kernel é mapear os dados originais num espaço de maior dimensionalidade, onde é mais provável que esses dados sejam linearmente separáveis. Recomenda-se a consulta da [documentação da classe `SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) para obter informação sobre os vários tipos de kernel que podem ser usados. Como exemplo, vamos usar um kernel [RBF](https://en.wikipedia.org/wiki/Radial_basis_function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac24c1-8538-428f-b46c-e1cbdf47318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svm_cls = SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a9919-d761-4d6e-80a5-ca33ddf3ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svm_cv_pred = cross_val_predict(rbf_svm_cls, X_train, y_train, cv=5)\n",
    "sns.scatterplot(pca_train, x='PC1', y='PC2', \n",
    "                hue=rbf_svm_cv_pred==y_train, palette={True: 'green', False: 'red'}, \n",
    "                style=rbf_svm_cv_pred==y_train, markers={True: 'P', False: 'X'},\n",
    "                legend=False\n",
    "               )\n",
    "plt.show()\n",
    "display_evaluation(y_train, rbf_svm_cv_pred, y.cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c1c54-2733-46ec-8cd9-3dc8a7e299a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['RBF SVM'] = rbf_svm_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a754cd-48e1-4402-a005-752c7483060b",
   "metadata": {},
   "source": [
    "### Redes Neuronais\n",
    "\n",
    "As redes neuronais são modelos computacionais inspirados no cérebro humano. Elas consistem em neurónios conectados em camadas. Cada neurónio recebe entradas, realiza cálculos e produz uma saída. Durante o treino, os pesos associados às conexões entre os neurónios são ajustados para que a rede possa aprender padrões nos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b7be56-cc69-4d1f-8768-83913f0fb2f7",
   "metadata": {},
   "source": [
    "#### Perceptrão\n",
    "\n",
    "O perceptrão é um classificador linear e é a versão mais simples de uma rede neuronal. No caso de um problema de classificação binária, consiste em apenas um neurónio. Em problemas multiclasse, há um neurónio por classe. Na biblioteca *scikit-learn* é implementado pela classe `Perceptron`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68270f12-851c-443d-8e3a-9797c1376bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa8fc5-c28c-4527-899f-ad7e9aa4f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cls = Perceptron()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c129aa50-2434-4674-8c39-e1ef60efc25a",
   "metadata": {},
   "source": [
    "**Nota**: Tal como no caso da regressão logística, o argumento `max_iter` pode ser usado para definir o número máximo de iterações. A regularização dos pesos pode ser controlada pelos argumentos `penalty` e `alpha`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1519fce-dd74-4b0d-ab2b-a8bf0ce7f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cv_pred = cross_val_predict(p_cls, X_train, y_train, cv=5)\n",
    "sns.scatterplot(pca_train, x='PC1', y='PC2', \n",
    "                hue=p_cv_pred==y_train, palette={True: 'green', False: 'red'}, \n",
    "                style=p_cv_pred==y_train, markers={True: 'P', False: 'X'},\n",
    "                legend=False\n",
    "               )\n",
    "plt.show()\n",
    "display_evaluation(y_train, p_cv_pred, y.cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3502b54e-d62a-4b91-9ba1-134cbbc66078",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['Perceptron'] = p_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd630d-f254-4566-85a0-24315edb4ed4",
   "metadata": {},
   "source": [
    "#### Redes Multicamada\n",
    "\n",
    "Redes neuronais com várias camadas podem ser usadas para aprender qualquer função e, como tal, lidar com conjuntos de dados que não são separáveis linearmente. Na biblioteca *scikit-learn*, a classe `MLPClassifier` implementa um perceptrão multicamada, sendo o número de camadas e neurónios por camada controlado pelo argumento `hidden_layer_sizes`. Como exemplo, vamos criar uma rede neuronal com uma camada escondida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604fe22-8d4a-412d-b845-f80b84eab999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d940bb56-982c-4dc0-886f-1a0318153d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_1h_cls = MLPClassifier(hidden_layer_sizes=(16,), max_iter=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcebff08-ed80-4c3a-b621-a30c3505e92f",
   "metadata": {},
   "source": [
    "**Nota**: As redes neuronais em geral e, especificamente, a classe `MLPClassifier` têm muitos hiperparâmetros configuráveis. Por exemplo:\n",
    "\n",
    "- `activation`: A função de activação aplicada pelos neurónios\n",
    "- `alpha`: Intensidade da regularização\n",
    "- `learning_rate`/`learning_rate_init`: Taxa de aprendizagem\n",
    "\n",
    "Recomenda-se a consulta da [documentação da classe](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) para obter informação sobre todas as possibilidades de configuração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befb6006-de84-4827-914f-8aa22527e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_1h_cv_pred = cross_val_predict(mlp_1h_cls, X_train, y_train, cv=5)\n",
    "sns.scatterplot(pca_train, x='PC1', y='PC2', \n",
    "                hue=mlp_1h_cv_pred==y_train, palette={True: 'green', False: 'red'}, \n",
    "                style=mlp_1h_cv_pred==y_train, markers={True: 'P', False: 'X'},\n",
    "                legend=False\n",
    "               )\n",
    "plt.show()\n",
    "display_evaluation(y_train, mlp_1h_cv_pred, y.cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9511ad2-2309-4053-ae78-b88090b102c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['MLP (1 hidden)'] = mlp_1h_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae43691-9e15-4983-a230-e3cdfa739f29",
   "metadata": {},
   "source": [
    "Quando criamos redes com várias camadas escondidas, o número de neurónios em cada camada pode variar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1afc618-bebe-424e-8ad3-81f6dacba825",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_2h_cls = MLPClassifier(hidden_layer_sizes=(16,8), max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6a3ab-6170-44bd-bf40-52cbcb59b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_2h_cv_pred = cross_val_predict(mlp_2h_cls, X_train, y_train, cv=5)\n",
    "sns.scatterplot(pca_train, x='PC1', y='PC2', \n",
    "                hue=mlp_2h_cv_pred==y_train, palette={True: 'green', False: 'red'}, \n",
    "                style=mlp_2h_cv_pred==y_train, markers={True: 'P', False: 'X'},\n",
    "                legend=False\n",
    "               )\n",
    "plt.show()\n",
    "display_evaluation(y_train, mlp_2h_cv_pred, y.cat.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535585d9-3d5d-4966-b4a2-bdc10cbddb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['MLP (2 hidden)'] = mlp_2h_cls.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833221de-3e4c-47d4-8f76-7e7fc5d28f81",
   "metadata": {},
   "source": [
    "## Teste\n",
    "\n",
    "Após explorar várias abordagens no conjunto de treino, podemos selecionar as melhores e avaliar o seu desempenho no conjunto de teste. O método `score` dos classificadores treinados usando a biblioteca *scikit-learn* pode ser usado para obter a taxa de acerto desse classificador num determinado conjunto de dados. Vamos usar esse método para calcular a taxa de acerto dos vários classificadores que guardamos no conjunto de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f8b5e-18d7-406c-8cfe-8c57124da222",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.Series({c_name: c.score(X_test, y_test) for c_name, c in classifiers.items()}, name='Accuracy')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f3372-f201-4363-a88e-a316367c07d2",
   "metadata": {},
   "source": [
    "Para calcular outras métricas, podemos usar o método `predict` para obter as previsões de um classificador num determinado conjunto de dados. Por exemplo, podemos usar esse método para obter as previsões do perceptrão para conjunto de teste e usar a função de avaliação que definimos anteriormente para analisar as suas falhas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62064be6-88e1-404e-b39b-ec9244499cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifiers['Perceptron'].predict(X_test)\n",
    "sns.scatterplot(pca_test, x='PC1', y='PC2', \n",
    "                hue=predictions==y_test, palette={True: 'green', False: 'red'}, \n",
    "                style=predictions==y_test, markers={True: 'P', False: 'X'},\n",
    "                legend=False\n",
    "               )\n",
    "plt.show()\n",
    "display_evaluation(y_test, predictions, y.cat.categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
